{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar=pd.read_csv('sonar.csv', names=range(0,61),header=None)\n",
    "sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsonar=pd.DataFrame(data=sonar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6       7       8  \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "          9  ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  Target  \n",
       "0    0.0090  0.0032       R  \n",
       "1    0.0052  0.0044       R  \n",
       "2    0.0095  0.0078       R  \n",
       "3    0.0040  0.0117       R  \n",
       "4    0.0107  0.0094       R  \n",
       "..      ...     ...     ...  \n",
       "203  0.0193  0.0157       M  \n",
       "204  0.0062  0.0067       M  \n",
       "205  0.0077  0.0031       M  \n",
       "206  0.0036  0.0048       M  \n",
       "207  0.0061  0.0115       M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsonar.rename(columns={60:'Target'}, inplace=True)\n",
    "dfsonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "56    0\n",
      "57    0\n",
      "58    0\n",
      "59    0\n",
      "60    0\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sonar.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAETCAYAAADJUJaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7xcVX338c+XBFCC3MJFJGhQAhoUIsSAVRQBJaAlEUHD0ypS2mgLLWpVoPiSesEHr1Rb5XkiBtHHchFFU4zQiAJtH7kEiIEQLjGgHAlJlZuIAjnn1z/WOmYY9pyz53LO2TPzfee1X7Nn7b1mrzlnsmadtdf6LUUEZmbWGzab6AKYmVnnuFI3M+shrtTNzHqIK3Uzsx7iSt3MrIe4Ujcz6yFjVqlLmivpLklrJJ0+VtcxM7NNNBbj1CVNAu4G3ggMADcBx0fEHR2/mJmZ/dFYtdTnAGsiYm1EPAVcDMwbo2uZmVk2VpX6bsD9Nc8HcpqZmY2hyWP0uipIe0Y/j6SFwEKAM7bb74Bjpkwfo6KYWS+ZPfC9ovqlKU//em3pfufNd3xx29cbT2NVqQ8Au9c8nwY8UHtCRCwCFgEsnzbfAWjMbPwMDU50CcbMWHW/3ATMkLSHpC2ABcCSMbqWmVlzYqj81mXGpKUeERslnQJcBUwCFkfEqrG4lplZ04a6r7Iua6y6X4iIpcDSsXp9M7NWxeDGiS7CmBmzSt3MrLK6sFulLFfqZtZ/fKO0mKTFkjZIur0mbQdJyyTdkx+3b7+YZmYd1MM3Stsd/fJ1YG5d2unA1RExA7g6Pzczq46hofJbl2mrUo+I64CH6pLnARfm/QuB+e1cw8ys0yKGSm/dZiz61HeJiHUAEbFO0s5jcA0zs9b18OiXCYunLmmhpOWSln/3d/dNVDHMrB8NDZbfusxYVOrrJe0KkB83FJ0UEYsiYnZEzHbcFzMbV75R2pQlwAl5/wTg+2NwDTOz1vXwjdK2+tQlXQQcAuwoaQA4CzgHuFTSScAvgePaLaSZWUd1YQu8rLYq9Yg4vsGhw9p5XTOzMdWFLfCyPKPUzPpODD090UUYM67Uzaz/9HBLveUbpZJ2l/QTSaslrZJ0ak53mAAzq7YOjn6RNFfSXZLWSHrWDHpJW0q6JB+/QdL0nL65pAsl3Zbr0TM68dbaGf2yEfj7iHgZcBBwsqSZOEyAmVVdh8apS5oEfBk4EpgJHJ/rwVonAQ9HxJ7AucCnc/pxwJYR8QrgAOA9wxV+O1qu1CNiXUTckvd/C6wmLS7tMAFmVm2da6nPAdZExNqIeAq4mFQH1qqtEy8DDpMk0rrNUyRNBp4LPAU81u5b68g49fzt8krgBurCBACFYQI8o9TMJszgxtJbbV2Vt4U1r7QbcH/N84GcRtE5EbEReBSYSqrgfwesIw3//lxE1MfSalrbN0olbQ18B3hfRDyWvoBG54WnzWzCNHGjtLauKlBU4dXXZ43OmQMMAi8Atgf+Q9KPImJt6cIVaDee+uakCv1bEfHdnFwqTICZ2YTp3IzSAWD3mufTgAcanZO7WrYlRbf9X8CVEfF0RGwA/guY3e5ba2f0i4CvAasj4gs1hxwmwMwqLWKw9DaKm4AZkvaQtAWwgFQH1qqtE48FfhwRQepyOVTJFNKAkzvbfW/tdL+8BngncJukFTntH3CYADOrug6NU4+IjZJOAa4CJgGLI2KVpI8DyyNiCanx+01Ja0gt9AU5+5eBC4DbSV00F0TEynbL1HKlHhH/SXFfEThMgJlVWQdjv0TEUmBpXdpHa/b/QEHjNiIeL0pvl2eUmln/6eFFMlypm1n/cZiAZ5P0HEk3SvpZDhPwsZy+R54Ke0+eGrtF54prZtYBXiSj0JPAoRGxHzALmCvpINIU2HNzmICHSVNkzcyqo4cXyWgnTEDkjn6AzfMWwKGkmVLgMAFmVkWu1ItJmpSHM24AlgE/Bx7JU2GheMrscF6HCTCzidHD3S/trnw0CMyStB1wOfCyotMa5HWYADObGB79MrKIeETSNaQZUdtJmpxb60VTZs3MJlYXdquU1c7ol51yCx1JzwUOJ4Xf/QlpKiw4TICZVZG7XwrtClyYg8RvBlwaEVdIugO4WNIngVtJU2TNzKqjh1vq7YQJWEmKoV6fvpYUUtLMrJpcqZuZ9ZDBUaMvdi1X6mbWf3q4pd72cnZ5rPqtkq7Izx0mwMyqrYdvlHZijdJTSaNehjlMgJlVm2eUFpM0DXgzcH5+LhwmwMyqLqL81mXaban/E/BhYPjrbCoOE2BmVeeW+rNJeguwISJurk0uOLVhmICImB0Rs4+ZMr3VYpiZNW9wY/mty7S7RunRko4CngNsQ2q5O0yAmVVaDHVft0pZ7YTePSMipkXEdNJCqj+OiD/DYQLMrOrc/dKU04AP5JWzp+IwAWZWNT08pLFTURqvAa7J+w4TYGbV1sPdL55Ramb9pwu7VcpypW5m/cexX4pJug/4LTAIbIyI2ZJ2AC4BpgP3AW+PiIfbK6aZWQf1cEu9EzdK3xARsyJidn5+OnB1DhNwdX5uZlYdQ1F+6zJjMfplHik8ADhMgJlVUQ+Pfmm3Ug/g3yXdLGlhTtslItYB5MedizI6TICZTZgebqm3e6P0NRHxgKSdgWWS7iybMSIWAYsAlk+b330/OTPrWrGxd2+UttVSj4gH8uMG4HLS+PT1knYFyI8b2i2kmVlHufvl2SRNkfS84X3gTcDtwBJSeABwmAAzqyJ3vxTaBbg8hVBnMvCvEXGlpJuASyWdBPwSOK79YpqZdVAPD2lsuVLP4QD2K0j/DXBYO4UyMxtTXdgCL8szSs2s/3RhX3lZ7S5nt52kyyTdKWm1pFdL2kHSsrzw9DJJ23eqsGZmnRAbB0tvo5E0V9JdktZIetZkS0lbSrokH79B0vS64y+U9LikD3bivbU7Tv2LwJUR8VJSV8xqPKPUzKquQzdKJU0CvgwcCcwEjpc0s+60k4CHI2JP4Fzg03XHzwV+2JH3RXujX7YBXkeOlx4RT0XEI3hGqZlVXedGv8wB1kTE2oh4CriYVAfWqq0TLwMOUx5hImk+sBZY1am31k5L/cXAfwMXSLpV0vl5aGOpGaVmZhOmc+PUdwPur3k+kNMKz8nLfD4KTM315WnAxzrynrJ2KvXJwP7AeRHxSuB3NNHV4jABZjZhmmip19ZVeVtY80oqePX65n2jcz4GnBsRj3fqbUF7o18GgIGIuCE/v4xUqa+XtGtErBtpRqnDBJjZRImN5Ue/1NZVBQaA3WueTwMeaHDOgKTJwLbAQ8CBwLGSPgNsBwxJ+kNE/EvpwhVoZ+HpB4H7Je2dkw4D7sAzSs2s6jq38PRNwAxJe0jaAlhAqgNr1daJxwI/juTgiJgeEdOBfwI+1W6FDu2PU/9b4Fv5zawFTiR9UXhGqZlVV4cmH0XERkmnAFcBk4DFEbFK0seB5RGxhDSY5JuS1pBa6As6cvEG2qrUI2IFMLvgkGeUmll1dXBGaUQsBZbWpX20Zv8PjNK4jYh/7FR5PKPUzPpORO/exnOlbmb9p4djv7Qz+WhvSStqtsckvc9hAsys6mLjUOmt27Qz+uWuvOD0LOAA4AnSQhkOE2Bm1dbD8dQ7tfD0YcDPI+IXOEyAmVXdUBNbl+lUn/oC4KK8/4wwAXn9UjOzyogubIGX1XZLPY9RPxr4dpP5HCbAzCaGu19GdCRwS0Ssz89LLTwdEYsiYnZEzD5myvQOFMPMrKQe7n7pRKV+PJu6XsBhAsys4mJjlN66TVt96pK2At4IvKcm+RwcJsDMKqyX+9TbDRPwBDC1Ls0LT5tZtXVht0pZnlFqZn2nh9eddqVuZn2ohyv1tm6USnq/pFWSbpd0kaTn5LjCN+QwAZfkIY9mZpURG8tv3aad2C+7AX8HzI6Il5NiCS8grZR9bg4T8DBpJW0zs8ro3BKl1dPukMbJwHPzEk1bAeuAQ0lL24HDBJhZBblSLxARvwI+Rxq2uI60QvbNwCN5xWwoXlnbzGxCuVIvkEPqzgP2AF4ATCHNLq1XOCDUYQLMbMKEym9dpp3ul8OBeyPivyPiaeC7wJ8A2+XuGCheWRtwmAAzmzhuqRf7JXCQpK0kiTTh6A7gJ6QVs8FhAsysgoY2qvTWbdrpU7+BdEP0FuC2/FqLgNOAD+SVs6eSVtI2M6uMCJXeuk27YQLOAs6qS14LzGnndc3MxlI3dquU5RmlZtZ3Yqj7WuBluVI3s74TvRukse0wAafmEAGrJL0vp+0gaVkOE7AsD300M6uMGFLprdu0M0795cBfkfrP9wPeImkGcDpwdQ4TcHV+bmZWGUODKr11m3Za6i8Dro+IJ/IM0muBt5ImJF2Yz3GYADOrHLfUi90OvE7S1LwC0lHA7sAuEbEOID/u3H4xzcw6p5eHNLYzTn01KSLjMuBK4GdA6UCVDhNgZhPFM0obiIivRcT+EfE64CHgHmC9pF0B8uOGBnkdJsDMJsRQqPTWbdpdeHrniNgg6YXAMcCrSQG+TiAtQO0wAWZWOUOD7UYdr652x6l/R9JU4Gng5Ih4WNI5wKWSTiLFhzmu3UKamXVSL49TbzdMwMEFab8hBfcyM6ukbhzVUpZnlJpZ3+nGvvKyXKmbWd/pxqGKZY16t0DSYkkbJN1ek1YYCkDJlyStkbRS0v5jWXgzs1ZElN9GI2mupLtyvfesGfSStpR0ST5+g6TpNcfOyOl3STqiE++tzC3grwNz69IahQI4EpiRt4XAeZ0opJlZJw0ObVZ6G4mkScCXSXXfTOB4STPrTjsJeDgi9gTOJc3vIZ+3ANiHVMd+Jb9eW0at1CPiOtIY9FqNQgHMA74RyfWkpe12bbeQZmad1MGW+hxgTUSsjYingItJ9WCt2vryMuCwvFrcPODiiHgyIu4F1tCBtShaHazZKBTAbsD9NecN5LRn8YxSM5sozUw+qq2r8raw5qXK1Hl/PCfHyXqUtCpc6fqyGZ2+UVp096Hwuy4iFpGWv2P5tPk9PGrUzKqmmRultXVVgTJ1XqNzSteXzWi1pd4oFMAAKajXsGnAA60Xz8ys8zoYJqBMnffHcyRNBrYldWmPSX3ZaqW+hBQCAJ4ZCmAJ8K48CuYg4NHhbhozs6qIJrZR3ATMkLSHpC1INz6X1J1TW18eC/w4IiKnL8ijY/YgDTC5sa03RonuF0kXAYcAO0oaIC003SgUwFJSCN41wBPAie0W0Mys00Yb1VJWRGyUdApwFTAJWBwRqyR9HFgeEUuArwHflLSG1EJfkPOuknQpcAcpwu3JETHYbpkUFQiC4D51Mytr9sD32p459B/PP7Z0nXPwg5d11Uwlzyg1s74Thfcoe4MrdTPrO0M93DfQapiA4yStkjQkaXbd+R2f9mpm1klDqPTWbVoNE3A7aVGM62oTx2raq5lZJw2i0lu3aSlMQESsjoi7Ck4fk2mvZmadFKj01m06vaaTwwSYWeUNNbF1m05X6k2FCfDC02Y2EXq5Uu/06BeHCTCzyuvGbpWyOt1SH5Npr2ZmnTSk8lu3aTVMwEPAPwM7AT+QtCIijhiraa9mZp3UjaNayhq1Uo+I4xscurzB+WcDZ7dTKDOzsdSNfeVleUapmfWdIfVxS93MrNf0cJSAlsMEfFbSnZJWSrpc0nY1xxwmwMwqrZeHNLYaJmAZ8PKI2Be4GzgDHCbAzLpDL49+aTVMwL/nBVQBrieNRweHCTCzLtDXsV9K+Avgh3nfYQLMrPL6uqU+Eklnksajf2s4qeA0hwkws0rp5T71lke/SDoBeAtwWGxaE89hAsys8vp69EsRSXOB04CjI+KJmkMOE2BmldfL3S+thgk4A9gSWKY0iP/6iHivwwSYWTfYOPopXavVMAFfG+F8hwkws0qLLmyBl+UZpWbWd7rxBmhZrtTNrO/0cqXeapiAT+QQASsk/bukF+R0SfpSDhOwUtL+Y1l4M7NWRBNbt2k1TMBnI2LfiJgFXAF8NKcfSRrxMgNYCJzXoXKamXVML49+aTVMwGM1T6ew6QttHvCNSK4HtpO0a6cKa2bWCRub2LpNyzNKJZ0t6X7gz9jUUneYADOrvH7vfikUEWdGxO6kEAGn5GSHCTCzyuvr7pcS/hV4W953mAAzq7xejv3SapiAGTVPjwbuzPtLgHflUTAHAY9GxLo2y2hm1lG93P3SapiAoyTtTfoi+wXw3nz6UuAoUhz1J4ATx6DMZmZt2diV1XU5HQ0TkKM1ntxuoczMxlLvVumeUWpmfagb+8rLamlGac2xD0oKSTvm555RamaVN16jXyTtIGmZpHvy4/YNzjshn3NPXqui/viSojq4SKszSpG0O/BG4Jc1yZ5RamaVN0SU3tp0OnB1RMwArs7Pn0HSDqR7lQeS1nQ+q7byl3QM8HjZC7Y0ozQ7F/gwz+ye8oxSM6u8cRz9Mg+4MO9fCMwvOOcIYFlEPBQRDwPLyA1pSVsDHwA+WfaCLfWpSzoa+FVE/CwvkjGs0YxSD2s0s8oYx9EvuwwP646IdZJ2LjhnpJn4nwA+TxpNWErT49QlbQWcyabQAM84XJBW+NNzmAAzmyjNtNRr66q8Lax9LUk/knR7wTavZHEK601Js4A9I+LyZt5bKy31lwB7AMOt9GnALZLm0MSM0ohYBCwCWD5tfi+PMDKzimlm9EttXdXg+OGNjklaL2nX3ErfFdhQcNoAaS7QsGnANcCrgQMk3Ueqq3eWdE1EHMIImm6pR8RtEbFzREyPiOm5QPtHxIN4RqmZdYFxvFG6BBgezXIC8P2Cc64C3iRp+3yD9E3AVRFxXkS8INezrwXuHq1Ch3JDGi8CfgrsLWlA0kkjnL4UWEuaUfpV4G9Ge30zs/E2jjdKzwHeKOke0mjBcwAkzZZ0PkBEPETqO78pbx/PaS1pdUZp7fHpNfueUWpmlTdek48i4jfAYQXpy4G/rHm+GFg8wuvcB7y8zDU9o9TM+s5gDwcKcKVuZn2nA33lldXqwtP/KOlXeeHpFZKOqjl2Rg4TcJekI8aq4GZmrerr0LukMAH/AnyjLv3ciPhcbYKkmcACYB/gBcCPJO0VEYMdKKuZWUf0dUt9hDABReYBF0fEkxFxL2kUzJw2ymdm1nFe+ajYKTkS4+Ka4DOlF542M5sog0Tprdu0WqmfR5pZOosU1+XzOd1hAsys8qKJf92mpUo9ItZHxGBEDJEmGQ13sTQVJiAiZkfE7GOmTG+lGGZmLXH3S526cLpvBYZHxiwBFkjaUtIepLjqN7ZXRDOzzhqKKL11m1YXnj4kRxAL4D7gPQARsUrSpcAdwEbgZI98MbOq6b6quryOLjydzz8bOLudQpmZjaVeHtLoGaVm1ne6cVRLWa7Uzazv9HJLvaUwATn9b3MogFWSPlOT7jABZlZpvTyksaUwAZLeQJo9um9EPDm87p7DBJhZN+jGoYpltRom4K+BcyLiyXzO8BJNDhNgZpUXEaW3btPqjNK9gIMl3SDpWkmvyukOE2BmlTeOy9mNu1Yr9cnA9sBBwIeAS5VWoXaYADOrvF6O/dLq6JcB4Lt5+bobJQ0BO9JkmADyCt3Lp83vvp+cmXWtbmyBl9VqS/17wKEAkvYCtgB+jcMEmFkX6OU+9VbDBCwGFudhjk8BJ+RWu8MEmFnl9fLol1bDBAD8eYPzHSbAzCqtG8efl+UZpWbWdwajd9vqrtTNrO/09Y3SojABki6RtCJv90laUXPMYQLMrNIcJqAuTEBEvGN4X9LngUfzvsMEmFnldePiF2W1GiYAgDzh6O3ARTnJYQLMrPKiia3btNunfjCwPiLuyc93A66vOe4wAWZWOX3dpz6K49nUSgeHCTCzLjAYQ6W3btNyS13SZOAY4ICaZIcJMLPKc0u92OHAnRExUJPmMAFmVnm9PPqlzJDGi4CfAntLGpB0Uj60gGd2vRARq4DhMAFX4jABZlZBfR37pVGYgIh4d4N0hwkws0rr5e4Xzyg1s77TjS3wslypm1nfGezhOI2thgmYJen6HCZguaQ5OV2SvpTDBKyUtP9YFt7MrBVDEaW3dkjaQdIySffkx+0bnHdCPuceSSfUpB8v6bZcn14pacfRrllm9MvXgbl1aZ8BPhYRs4CP5ucAR5JGvMwAFgLnlXh9M7NxNY6jX04Hro6IGcDV+fkzSNqBtE7FgaQZ+GdJ2j4PG/8i8IaI2BdYCZwy2gVbDRMQwDZ5f1s2jUWfB3wjkuuB7STtOto1zMzG03i11El14oV5/0JgfsE5RwDLIuKhiHgYWEZqSA+v+zwlh2TZhgbzfmq1Ok79fcBnJd0PfA44I6fvBtxfc17DMAGeUWpmE6WZlnptXZW3hU1capeIWAeQH3cuOKew3oyIp4G/Bm4jVeYzga+NdsFWb5T+NfD+iPiOpLfnCx1OE2ECPKPUzCZKM9P/a+uqIpJ+BDy/4NCZJS9RWG9K2pxU174SWAv8M6kB/cmRXqzVSv0E4NS8/23g/LxfOkyAmdlE6WTo3Yg4vNExSesl7RoR63JX9IaC0wZI60APmwZcA8zKr//z/FqXUtAnX6/V7pcHgNfn/UOB4SiNS4B35VEwBwGPDv/pYWZWFeN4o3QJqRFMfvx+wTlXAW/KN0e3B96U034FzJS0Uz7vjcDq0S44aks9hwk4BNhR0gDpLu1fAV/Md2f/QBrpArAUOIoUR/0J4MTRXt/MbLzF+EVfPAe4NIdX+SVwHICk2cB7I+IvI+IhSZ8Absp5Ph4RD+XzPgZcJ+lp4BfAu0e7oKows8p96mZW1uyB7xX1QTflRVP3LV3n/OI3K9u+3njyjFIz6ztVaMyOFVfqZtZ3unHxi7JaDROwn6Sf5umr/yZpm5pjZ+QwAXdJOmKsCm5m1qpxnHw07loNE3A+cHpEvAK4HPgQgKSZpDjr++Q8X5E0qWOlNTPrgL5eJKNBmIC9gevy/jLgbXl/HnBxRDwZEfeSRsHM6VBZzcw6opcXyWh1nPrtwNF5/zg2TThymAAzq7whovTWbVqt1P8COFnSzcDzgKdyelNhAiJidkTMPmbK9BaLYWbWvMGhodJbt2lp9EtE3Ema9YSkvYA350MOE2BmldeN3SpltdRSl7RzftwM+Ajwf/KhJcACSVtK2oMUV/3GThTUzKxTern7pdUwAVtLOjmf8l3gAoCIWJWDztwBbAROjojBsSi4mVmrerml7jABZtZVOhEmYOut9ihd5zz+xL0OE2BmVmXdOP68LFfqZtZ3unFUS1llwgTsLuknklZLWiXp1JxeuEp2jqX+pRwqYKWk/cf6TZiZNaOvZ5SSbnj+fUS8DDiIND59Jo1XyT6SNOplBinO+nkdL7WZWRv6ekZpRKyLiFvy/m9JK2/sRuNVsucB34jkemC7vIyTmVkl9HKl3uybm05avWMb4JG6Yw/nxyuA19akXw3MLnithcDyvC0cTmumPLWv5Tz+2fln1x15xvta/bY18wPdGrgZOCY/b1Sp/6CgUj+g5DWWt/gBaTqf81S/fFXOU/XyVTnPeF+r37ZSM0olbQ58B/hWRHw3J68f7lapWyXboQLMzCZImdEvAr4GrI6IL9QcarRK9hLgXXkUzEHAoxGxroNlNjOzBsqMU38N8E7gNkkrcto/0GCVbGApcBQplvoTwIlNlGdRE+e2m895xvdavZZnPK/Va3nG+1p9pRJhAszMrDNajaduZmYV5ErdzKyHuFI3s0qSdEyZNHumCe1Tl/RS0gzU3UjL3j0ALImI1SPkmQNERNyUwxXMBe6MiKUNzj+QNHLnMUnPJYUz2J8U8/1TEfHoCNd6CfBW0hDNjcA9wEUj5ekHknaOiA2jn2m9biw/C5JuiYj969JujogDxuJ6vWLCWuqSTgMuJq1reiNwU96/SNLpDfKcBXwJOE/S/wb+hTQp6nRJZza41GLSKByALwLbAp/OaReMUL6/I63o9BzgVcBzSZX7TyUdUvqNdgFJPxzh2A5121TgRknbS9qhQZ5bJH0kfymWLcNkSe+RdGUOBPczST+U9N48T6Ioz1aSPizpQ5KeI+ndkpZI+oykrRvkOUXSjnl/T0nXSXpE0g2SXtEgz2aS/kLSD3K5bpZ08UifA0mT8vv5hKTX1B37SIM8+9bsb55/hkskfUrSViNc68WSFkv6pKStJX1V0u2Svi1peqN8I7xe4edhHD8LR0g6F9hN0hdqtvOB3g2v2CET1lKXdDewT0Q8XZe+BbAqUqCw+jy3AbOALYEHgWk1LfAbImLfgjyrIwUje9Y3v6QVETGrQfluA2ZFxGD+D7U0Ig6R9ELg+xHxyoI82wBnkCZc/TAi/rXm2Fci4m8K8syNiCvz/rbAF0hfIrcD74+I9Q3KNxv4LPCrfM3FwBzgbtJ06lvrzm8ULVPAFRFRGJ9H0hDwi7rkaaRJZhERLy7Icy9pstrbSb+ni4BLIqLhJDSlFbYeIcURGqi5zgnADhHxjoI8lwL3k75w9ybFJboU+FPg+RHxzoI8qyJin7z/A+D8iLg8V9BnR8RrCvJckH8GPwKOBR4D/gM4jfRZ+OeCPOcDW5EaLO8Ero2ID+Rjz2qB1qdL+jwwldTwmA9MjYh3FfzokHQd6We8LfDnOc+lpHWE/ywiDi3I0/TnYRw/C68k/TX9UeDjNYd+C/w4In7dKK/RXOyXTm7AncCLCtJfBNzVIM+tRfv5+YoGeb4NnJj3LyDHoQH2Am4aoXy3AVvm/e2Bm2uO3d4gz3dI4/fnkyZhfafmNW5pkOeWmv3zgU/mn8H7ge+NUL4bSRExjydVbMfm9MOAnxacPwj8GPhJwfb7Ea7zQeBK4BU1afeO8rutfU8HA18h/Yf+CQ3idzT6nedjdzdIX5EflV9fNc9Xjnad+t//CHlW1j2/Pj9uSeraGzEPaT7IItLSj1vWf3YbfL5XAJuP9n4K8v2y0bF2Pw/j9VmoOf85wBbAniOd563u5zZhF0594WuAH+YP/KL8gVkDzG2Q5wZgq7y/WU36tjSuNLcFvg78POd/GlgLXAvsN0L5TgVW5nLdyaYvhp2A6xrkWVH3/Ezgv0gtrjKVen3+wi+qfKyp/8iklv+MBq91/yi/q2mkL8cvAM8D1o5y/sj2uu0AAAXuSURBVLPeKzAp/84vaJDnetIEttrf62bAO0h/hY348wYW1x37WYM8Z+fPw4tJk+jeB7yQNEnuigZ5bgZekvf3r/39A3c0yHNnQdpZ+fNwT4M8a0n3cN5G3ZdFo/dTU769SH/h/ZpNDZc9afxF1dLnYTw+CzXnvRm4i/zFQfor/fKR8nibwEo9/5I2I8Vofxvpz9qDgEkjnL9lg/QdqWk9NDjnecB+wAHALiXLt08u10tLnr+6tlLKaScAq4BfNMgzAHwA+Pv8n1o1x0Zqnf2U9Of1caQ/iefn9NdTEPgov4+9G7zW/JLv709Jle+Do5x3cQufhenAJaQYQnfnbUNO26NBnvOBrQvSXwL85wjXejfpC/7XpD/p7wA+BWzb4PxDSbOm7wbuBQ7M6TsBn2mQ5/9R0DgB/hJ4ukGer5P+mhzedsnpzyetXdDo/RyWK7/VwGtJfyHek39+hb/bdj8PY/lZqMl7M7Adz2zA3Nbq6/XLNuEF6KUN+AxweEH6XBq3zs6q23bK6c8nxaVvdK39gKtIf+m8lHQT+JH8BfInDfK8NFcAW9eXb5T39cd8pP7rl4+Wr5VrAQeS7gtMzZXTB4GjRinbHOBVeX8m6QvyzdR8OY6SZx/SF+po13l1wXVGzFPwGg1/n53Mk/NdQV0DY5TzX5vf05uayHMw8JEm85S+Dpu6uWor9YYNHW9pc5iAcSLpxIi4YKzzNMqXR/OcTGrNzQJOjYjv52OFN+5azSfpb4FTmsxzFukewWRgGanivRY4HLgqIs4ukedA4Jom87RynTJ5ltQnAW8g9WMTEUeXyAPpr4SGeVrNJ+nGiJiT9/+K9Du+nPTX379FxDkl8vwN8L0m84x6nZq8F5AaLWeS7lOdSup+Xdgoj+GW+nht1PV7j1WeRvlIN363zvvTSYuTnJqfF95MazVfG3kmkUaMPAZsk9OfS+N+4SrnuZXUBXMIqUvsEGBd3n99p/K0c62a/ZvY9BfiFBp0cYxXnprzp5CGH99KunH8afI9NW+NtzJRGq0kSSsbHQJ26VSeFvNNiojHASLivjyE7zJJL8p5GmklXyt5NkbEIPCEpJ9HxGM5/+/zULpuy3MAqWV5JvChiFgh6fcRcW2D81vN02q+zZQWi9+M1FX13/k9/U7SxgnOw/A5pGGjp410nj2TK/XO2gU4Ani4Ll3A/+9gnlbyPShpVkSsAIiIxyW9hTS+vXDSTRv5WsnzlKStIuIJUiWV3kwau9+o4qxsnogYAs6V9O38uJ5R/r+1kqeNfNuSbkQKCEnPj4gHlSZtNfriHa88AEi6nDTTvNajpL/8vhoRT43yHvuSK/XOuoLU7bCi/oCkazqYp5V87yKFOvijiNhIWtDk/45wnVbytZLndRHxZD63tqLcnE2LsXRTHvL5A8Bxkt5M6roZVSt5ms0XEdMbHBoiDaucsDw17icNGLgoP38H8BCwL/BVRvnZ9yvfKDWzSpJ0bUS8vua5SDNzXyfpjoiYOYHFqyxHaTSzqtpF0rSa5y8gzQ0AeHICytMV3P1iZlX1YVIAvTtJ/e97AadImgJ8a0JLVmHufjGzypG0GSnswUrSZC+RAv39fkIL1gVcqZtZJUm6PiIOmuhydBv3qZtZVS2TNG+iC9Ft3FI3s0qS9DBpnPuTwO/JY90jonBBDktcqZtZJUmaVJSeZ/daA67Uzayy8qzdl5AWzAAgIkaaad33PKTRzCpJ0kmkML27kYKqvYoUw/2QCSxW5flGqZlV1fuA2cB9EXEwKe7OuoktUvW5UjezqvrD8Lh0SVtExCrS4is2Ane/mFmlSJqcA8Ctk7Qd8G/AVZIeAtZPbOmqzzdKzaxSilbHknQYaXjjD4YjZloxt9TNrGqeFWc9Iq6eiIJ0I1fqZlY1O0n6QKODEfGF8SxMt3GlbmZVMwkYdWUkK+Y+dTOrlKI+dSvPQxrNrGrcQm+DW+pmVimSdoiIhya6HN3KlbqZWQ9x94uZWQ9xpW5m1kNcqZuZ9RBX6mZmPcSVuplZD/kfjv0nNxQqOO0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(dfsonar.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsonar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         float64\n",
       "1         float64\n",
       "2         float64\n",
       "3         float64\n",
       "4         float64\n",
       "           ...   \n",
       "56        float64\n",
       "57        float64\n",
       "58        float64\n",
       "59        float64\n",
       "Target     object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsonar.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Target\",data=dfsonar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dfsonar.iloc[:,0:60]\n",
    "y=dfsonar[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(y)\n",
    "y=le.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def maxf1score(cm,x,y):\n",
    "    maxf1=0\n",
    "    rs=0\n",
    "    for rstate in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=rstate,test_size=0.20,stratify=y)\n",
    "        cm.fit(x,y)\n",
    "        predicty=cm.predict(x_test)\n",
    "        Newf1=f1_score(y_test,predicty)\n",
    "        if Newf1>maxf1:\n",
    "            maxf1=Newf1\n",
    "            rs=rstate\n",
    "    print(\"Maximum f1 score is: \", maxf1,\"at random state: \", rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum f1 score is:  0.9189189189189189 at random state:  66\n"
     ]
    }
   ],
   "source": [
    "Logreg=LogisticRegression()\n",
    "maxf1score(Logreg,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "Logreg=LogisticRegression()\n",
    "C = [0.001,0.01,0.1,1,10,100,1000]\n",
    "penalty = ['l1', 'l2']\n",
    "hyperparametersLogreg=dict(C=C, penalty=penalty)\n",
    "gridlr=GridSearchCV(Logreg, hyperparametersLogreg, cv=5, scoring='f1')\n",
    "gridlr.fit(x,y)\n",
    "print(gridlr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score for Logistic Regression after cross validation:  0.6109754471310535\n",
      "Standard deviation for Logistic Regression from mean f1 score is :  0.1219092614949577\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean f1 score for Logistic Regression after cross validation: \", cross_val_score(Logreg,x,y,cv=5,scoring=\"f1\").mean())\n",
    "print(\"Standard deviation for Logistic Regression from mean f1 score is : \", cross_val_score(Logreg,x,y,cv=5,scoring=\"f1\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum f1 score is:  1.0 at random state:  42\n"
     ]
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "maxf1score(dtc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "hyperparametersdtc={'criterion':['gini','entropy'],'max_depth':range(1,10)}\n",
    "griddtc=GridSearchCV(dtc, hyperparametersdtc, cv=5, scoring='f1')\n",
    "griddtc.fit(x,y)\n",
    "print(griddtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score for Logistic Regression after cross validation:  0.5981244230024718\n",
      "Standard deviation for Logistic Regression from mean f1 score is :  0.09889121524893951\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean f1 score for Logistic Regression after cross validation: \", cross_val_score(dtc,x,y,cv=5,scoring=\"f1\").mean())\n",
    "print(\"Standard deviation for Logistic Regression from mean f1 score is : \", cross_val_score(dtc,x,y,cv=5,scoring=\"f1\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum f1 score is:  0.787878787878788 at random state:  93\n"
     ]
    }
   ],
   "source": [
    "svc=SVC()\n",
    "maxf1score(svc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc=SVC()\n",
    "hyperparameterssvc = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','poly']}\n",
    "gridsvc=GridSearchCV(svc, hyperparameterssvc, cv=5, scoring='f1')\n",
    "gridsvc.fit(x,y)\n",
    "print(gridsvc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score for Logistic Regression after cross validation:  0.31006043270230915\n",
      "Standard deviation for Logistic Regression from mean f1 score is :  0.08533675167448813\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean f1 score for Logistic Regression after cross validation: \", cross_val_score(svc,x,y,cv=5,scoring=\"f1\").mean())\n",
    "print(\"Standard deviation for Logistic Regression from mean f1 score is : \", cross_val_score(svc,x,y,cv=5,scoring=\"f1\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum f1 score is:  0.9230769230769231 at random state:  53\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "maxf1score(knn,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "k_range = list(range(1,50))\n",
    "hyperparametersknn=dict(n_neighbors=k_range)\n",
    "gridknn=GridSearchCV(knn, hyperparametersknn, cv=5, scoring='f1')\n",
    "gridknn.fit(x,y)\n",
    "print(gridknn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score for Logistic Regression after cross validation:  0.5236528644356211\n",
      "Standard deviation for Logistic Regression from mean f1 score is :  0.10543633866610798\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean f1 score for Logistic Regression after cross validation: \", cross_val_score(knn,x,y,cv=5,scoring=\"f1\").mean())\n",
    "print(\"Standard deviation for Logistic Regression from mean f1 score is : \", cross_val_score(knn,x,y,cv=5,scoring=\"f1\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above analysis indicates that Logistic regression has the highest f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  1]\n",
      " [ 3 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91        22\n",
      "           1       0.94      0.85      0.89        20\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.91      0.90      0.90        42\n",
      "weighted avg       0.91      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=66,test_size=.20,stratify=y)\n",
    "Logreg.fit(x_train,y_train)\n",
    "predicty=Logreg.predict(x_test)\n",
    "print(confusion_matrix(y_test,predicty))\n",
    "print(classification_report(y_test,predicty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonar_datset_knn.pkl']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(knn,'sonar_datset_knn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
